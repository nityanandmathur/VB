{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.structures.image_list import ImageList\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.modeling.box_regression import Box2BoxTransform\n",
    "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputs\n",
    "from detectron2.structures.boxes import Boxes\n",
    "from detectron2.layers import nms\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(10000,256,device=device)\n",
    "# y = x.to(device)\n",
    "# print(x[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "\n",
    "def load_config_and_model_weights(cfg_path):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(cfg_path))\n",
    "\n",
    "    # ROI HEADS SCORE THRESHOLD\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "\n",
    "    # Comment the next line if you're using 'cuda'\n",
    "    cfg['MODEL']['DEVICE']='cpu'\n",
    "\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(cfg_path)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "cfg = load_config_and_model_weights(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def get_model(cfg):\n",
    "    # build model\n",
    "    model = build_model(cfg)\n",
    "\n",
    "    # load weights\n",
    "    checkpointer = DetectionCheckpointer(model)\n",
    "    checkpointer.load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "    # eval mode\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = get_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "# image1 = []\n",
    "# image2 = []\n",
    "# image3 = []\n",
    "# image4 = []\n",
    "\n",
    "# img_dir1 = '/home/btech/nityanand.mathur/hateful_memes/dataset/train/hateful'\n",
    "# img_dir2= '/home/btech/nityanand.mathur/hateful_memes/dataset/train/non_hateful'\n",
    "# img_dir3= '/home/btech/nityanand.mathur/hateful_memes/dataset/val/hateful'\n",
    "# img_dir4= '/home/btech/nityanand.mathur/hateful_memes/dataset/val/non_hateful'\n",
    "# image = '/home/btech/nityanand.mathur/hateful_memes/dataset/train/hateful/01235.png'\n",
    "# img = cv2.imread(image)\n",
    "\n",
    "# data_path1 = os.path.join(img_dir1,'*g')\n",
    "# files = glob.glob(data_path1)\n",
    "# for f1 in files:\n",
    "#     img1 = cv2.imread(f1)\n",
    "#     image1.append(img1)\n",
    "\n",
    "\n",
    "\n",
    "# data_path2 = os.path.join(img_dir2,'*g')\n",
    "# files = glob.glob(data_path2)\n",
    "# for f1 in files:\n",
    "#     img2 = cv2.imread(f1)\n",
    "#     image2.append(img2)\n",
    "\n",
    "\n",
    "# data_path3 = os.path.join(img_dir3,'*g')\n",
    "# files = glob.glob(data_path3)\n",
    "# for f1 in files:\n",
    "#     img3= cv2.imread(f1)\n",
    "#     image3.append(img3)\n",
    "\n",
    "\n",
    "# data_path4 = os.path.join(img_dir4,'*g')\n",
    "# files = glob.glob(data_path4)\n",
    "# for f1 in files:\n",
    "#     img4 = cv2.imread(f1)\n",
    "#     image4.append(img4)\n",
    "\n",
    "# image_bgr1 = []\n",
    "# for i in image1:\n",
    "#     img_bgr = cv2.cvtColor(i,cv2.COLOR_RGB2BGR)\n",
    "#     image_bgr1.append(img_bgr)\n",
    "\n",
    "# image_bgr2 = []\n",
    "# for i in image2:\n",
    "#     img_bgr = cv2.cvtColor(i,cv2.COLOR_RGB2BGR)\n",
    "#     image_bgr2.append(img_bgr)\n",
    "\n",
    "# image_bgr3 = []\n",
    "# for i in image3:\n",
    "#     img_bgr = cv2.cvtColor(i,cv2.COLOR_RGB2BGR)\n",
    "#     image_bgr3.append(img_bgr)\n",
    "\n",
    "# image_bgr4 = []\n",
    "# for i in image4:\n",
    "#     img_bgr = cv2.cvtColor(i,cv2.COLOR_RGB2BGR)\n",
    "#     image_bgr4.append(img_bgr)\n",
    "\n",
    "# del(image1)\n",
    "# del(image2)\n",
    "# del(image3)\n",
    "# del(image4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_inputs(cfg, img_list):\n",
    "    # Resizing the image according to the configuration\n",
    "    transform_gen = T.ResizeShortestEdge(\n",
    "                [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    "            )\n",
    "    img_list = [transform_gen.get_transform(img).apply_image(img) for img in img_list]\n",
    "\n",
    "    # Convert to C,H,W format\n",
    "    convert_to_tensor = lambda x: torch.Tensor(x.astype(\"float32\").transpose(2, 0, 1))#.to(device=device)\n",
    "\n",
    "    batched_inputs = [{\"image\":convert_to_tensor(img), \"height\": img.shape[0], \"width\": img.shape[1]} for img in img_list]\n",
    "\n",
    "    # Normalizing the image\n",
    "    num_channels = len(cfg.MODEL.PIXEL_MEAN)\n",
    "    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).view(num_channels, 1, 1)#.to(device=device)\n",
    "    pixel_std = torch.Tensor(cfg.MODEL.PIXEL_STD).view(num_channels, 1, 1)#.to(device=device)\n",
    "    normalizer = lambda x: (x - pixel_mean) / pixel_std\n",
    "    images = [normalizer(x[\"image\"]) for x in batched_inputs]\n",
    "\n",
    "    # Convert to ImageList\n",
    "    images =  ImageList.from_tensors(images,model.backbone.size_divisibility)\n",
    "    \n",
    "    return images, batched_inputs\n",
    "\n",
    "def get_features(model, images):\n",
    "    features = model.backbone(images.tensor)\n",
    "    return features\n",
    "\n",
    "    \n",
    "def get_proposals(model, images, features):\n",
    "    proposals, _ = model.proposal_generator(images, features)\n",
    "    return proposals\n",
    "\n",
    "\n",
    "def get_box_features(model, features, proposals):\n",
    "    features_list = [features[f] for f in ['p2', 'p3', 'p4', 'p5']]\n",
    "    box_features = model.roi_heads.box_pooler(features_list, [x.proposal_boxes for x in proposals])\n",
    "    box_features = model.roi_heads.box_head.flatten(box_features)\n",
    "    box_features = model.roi_heads.box_head.fc1(box_features)\n",
    "    box_features = model.roi_heads.box_head.fc_relu1(box_features)\n",
    "    box_features = model.roi_heads.box_head.fc2(box_features)\n",
    "\n",
    "    box_features = box_features.reshape(1, 1000, 1024) # depends on your config and batch size\n",
    "    return box_features, features_list\n",
    "\n",
    "\n",
    "def get_prediction_logits(model, features_list, proposals):\n",
    "    cls_features = model.roi_heads.box_pooler(features_list, [x.proposal_boxes for x in proposals])\n",
    "    cls_features = model.roi_heads.box_head(cls_features)\n",
    "    pred_class_logits, pred_proposal_deltas = model.roi_heads.box_predictor(cls_features)\n",
    "    return pred_class_logits, pred_proposal_deltas\n",
    "\n",
    "\n",
    "def get_box_scores(cfg, pred_class_logits, pred_proposal_deltas):\n",
    "    box2box_transform = Box2BoxTransform(weights=cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS)\n",
    "    smooth_l1_beta = cfg.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA\n",
    "\n",
    "    outputs = FastRCNNOutputs(\n",
    "        box2box_transform,\n",
    "        pred_class_logits,\n",
    "        pred_proposal_deltas,\n",
    "        proposals,\n",
    "        smooth_l1_beta,\n",
    "    )\n",
    "\n",
    "    boxes = outputs.predict_boxes()\n",
    "    scores = outputs.predict_probs()\n",
    "    image_shapes = outputs.image_shapes\n",
    "\n",
    "    return boxes, scores, image_shapes\n",
    "\n",
    "\n",
    "def get_output_boxes(boxes, batched_inputs, image_size):\n",
    "    proposal_boxes = boxes.reshape(-1, 4).clone()\n",
    "    scale_x, scale_y = (batched_inputs[\"width\"] / image_size[1], batched_inputs[\"height\"] / image_size[0])\n",
    "    output_boxes = Boxes(proposal_boxes)\n",
    "\n",
    "    output_boxes.scale(scale_x, scale_y)\n",
    "    output_boxes.clip(image_size)\n",
    "\n",
    "    return output_boxes\n",
    "\n",
    "\n",
    "def select_boxes(cfg, output_boxes, scores):\n",
    "    test_score_thresh = cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST\n",
    "    test_nms_thresh = cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST\n",
    "    cls_prob = scores.detach().cpu() #added CPU\n",
    "    cls_boxes = output_boxes.tensor.detach().cpu().reshape(1000,80,4) # added CPU \n",
    "    max_conf = torch.zeros((cls_boxes.shape[0]))\n",
    "    for cls_ind in range(0, cls_prob.shape[1]-1):\n",
    "        cls_scores = cls_prob[:, cls_ind+1]\n",
    "        det_boxes = cls_boxes[:,cls_ind,:]\n",
    "        keep = np.array(nms(det_boxes, cls_scores, test_nms_thresh))\n",
    "        max_conf[keep] = torch.where(cls_scores[keep] > max_conf[keep], cls_scores[keep], max_conf[keep])\n",
    "    keep_boxes = torch.where(max_conf >= test_score_thresh)[0]\n",
    "    return keep_boxes, max_conf\n",
    "\n",
    "def filter_boxes(keep_boxes, max_conf, min_boxes, max_boxes):\n",
    "    if len(keep_boxes) < min_boxes:\n",
    "        keep_boxes = np.argsort(max_conf).numpy()[::-1][:min_boxes]\n",
    "    elif len(keep_boxes) > max_boxes:\n",
    "        keep_boxes = np.argsort(max_conf).numpy()[::-1][:max_boxes]\n",
    "    return keep_boxes\n",
    "\n",
    "\n",
    "def get_visual_embeds(box_features, keep_boxes):\n",
    "    return box_features[keep_boxes.copy()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output4 = []\n",
    "#f = open(\"output2.txt\", \"a\")\n",
    "import json\n",
    "\n",
    "# Opening JSON file\n",
    "f = open('hateful_memes/train.jsonl', 'r')\n",
    "data = json.load(f)\n",
    "\n",
    "for i in range(1):    \n",
    "    #reading from json file and converting from RGB to BGR\n",
    "    img_path = 'hateful_memes/' + data[i]['img']\n",
    "    print(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #loading the image and converting to tensor\n",
    "    images, batched_inputs = prepare_image_inputs(cfg, [img_bgr])\n",
    "    features = get_features(model, images)\n",
    "    features.keys()\n",
    "    proposals = get_proposals(model, images, features)\n",
    "    box_features, features_list = get_box_features(model, features, proposals)\n",
    "    pred_class_logits, pred_proposal_deltas = get_prediction_logits(model, features_list, proposals)\n",
    "    boxes, scores, image_shapes = get_box_scores(cfg, pred_class_logits, pred_proposal_deltas)\n",
    "    output_boxes = [get_output_boxes(boxes[i], batched_inputs[i], proposals[i].image_size) for i in range(len(proposals))]\n",
    "    temp = [select_boxes(cfg, output_boxes[i], scores[i]) for i in range(len(scores))]\n",
    "    keep_boxes, max_conf = [],[]\n",
    "    for keep_box, mx_conf in temp:\n",
    "        keep_boxes.append(keep_box)\n",
    "        max_conf.append(mx_conf)\n",
    "    MIN_BOXES=10\n",
    "    MAX_BOXES=100\n",
    "    keep_boxes = [filter_boxes(keep_box, mx_conf, MIN_BOXES, MAX_BOXES) for keep_box, mx_conf in zip(keep_boxes, max_conf)]\n",
    "\n",
    "    from transformers import BertTokenizer, VisualBertModel\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model1 = VisualBertModel.from_pretrained(\"uclanlp/visualbert-nlvr2-coco-pre\")\n",
    "    #tokenizing text inputs\n",
    "    inputs = tokenizer(data[i]['text'], return_tensors=\"pt\") \n",
    "    #finding visual embeddings\n",
    "    visual_embeds = [get_visual_embeds(box_feature, keep_box) for box_feature, keep_box in zip(box_features, keep_boxes)]\n",
    "    visual_embeds = torch.stack(visual_embeds)\n",
    "    visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.long)\n",
    "    visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.long)\n",
    "    #adding both embeddings\n",
    "    inputs.update(\n",
    "        {\n",
    "            \"visual_embeds\": visual_embeds,\n",
    "            \"visual_token_type_ids\": visual_token_type_ids,\n",
    "            \"visual_attention_mask\": visual_attention_mask,\n",
    "        }\n",
    "    )\n",
    "    outputs = model1(**inputs)  \n",
    "    # f.write(str(outputs))\n",
    "    #print(outputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    #hs.write(str(last_hidden_states))\n",
    "# print(last_hidden_states)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('hateful_memes/test_unseen.jsonl', 'r')\n",
    "data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 110, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.70977890e-01  8.93255249e-02  4.29117411e-01  7.05169961e-02\n",
      "  6.70925975e-02  2.35964090e-01  1.08436227e-01  3.09289359e-02\n",
      " -1.10481910e-01 -1.46518881e-02  1.15664676e-01 -1.90246850e-03\n",
      " -6.09312728e-02  2.71173596e-01  1.50237873e-01  2.80442625e-01\n",
      " -3.19435000e-02  3.48602623e-01 -1.44309357e-01 -2.43468776e-01\n",
      "  2.34100968e-01 -3.70606519e-02  9.49920192e-02 -1.81320652e-01\n",
      "  1.03148855e-01 -6.84947371e-02  1.05372965e-01  2.54553169e-01\n",
      "  2.07433283e-01  1.23621553e-01  4.13727701e-01  1.03580318e-01\n",
      "  2.03460291e-01 -1.31554246e-01 -7.31589347e-02 -1.80084437e-01\n",
      " -8.03028867e-02  6.24556188e-03  2.37772554e-01 -1.38537258e-01\n",
      " -7.65928328e-02 -1.48852482e-01 -1.54305063e-02  1.21296272e-02\n",
      "  4.01995778e-01  1.83955953e-01 -1.37234533e+00 -3.98194697e-03\n",
      " -6.11493349e-01  7.13877100e-03  1.44077390e-01  8.97097141e-02\n",
      "  9.59546641e-02  2.74929821e-01 -9.71964225e-02 -6.48421720e-02\n",
      "  1.21408574e-01  1.99563876e-01  1.16951875e-01 -6.64323047e-02\n",
      "  5.73199987e-01 -2.17649639e-01 -2.79875398e-01 -2.10031439e-02\n",
      " -1.02977753e-01 -3.40068549e-01  1.36489913e-01  6.59895614e-02\n",
      "  6.90941885e-02  1.37370482e-01  9.07196403e-02 -1.05647631e-01\n",
      "  2.07117617e-01 -1.48551330e-01 -7.34564066e-02  2.00131327e-01\n",
      "  7.28517920e-02 -2.09758475e-01  5.18447980e-02  1.50263757e-01\n",
      " -2.26277128e-01  1.34768113e-01  3.19353938e-01  1.37744904e-01\n",
      " -2.52914935e-01  1.19290724e-01  3.56251359e-01  1.24220066e-01\n",
      " -3.31962973e-01  2.39058390e-01 -3.80002856e-01  1.43550798e-01\n",
      "  3.11185658e-01  1.33221328e-01 -8.38492736e-02 -3.44720662e-01\n",
      " -1.59608066e-01 -3.87385964e-01 -9.35510099e-02  1.21813871e-01\n",
      " -5.80293238e-01  7.08105639e-02 -8.19791779e-02 -8.98745470e-03\n",
      "  9.05318558e-02  2.03416385e-02 -1.00265637e-01 -1.95204303e-01\n",
      "  1.19710274e-01 -2.85987949e+00  4.17623609e-01  2.11072892e-01\n",
      " -1.43555971e-02 -1.26850799e-01 -2.42260948e-01 -1.10698156e-01\n",
      "  1.39660716e-01  1.23777732e-01 -9.16118175e-02  2.60273308e-01\n",
      " -2.66760975e-01  5.62210500e-01  1.69151872e-01  1.42660737e-01\n",
      "  2.49347195e-01  1.86010137e-01  2.24470437e-01 -1.35662645e-01\n",
      "  8.31621364e-02 -1.01966001e-01  5.79513535e-02 -2.04869807e-01\n",
      " -5.57036437e-02  9.47139487e-02 -1.69668362e-01 -1.14432178e-01\n",
      "  4.17558774e-02 -2.60226309e-01  1.17050000e-01 -1.59760565e-03\n",
      "  2.01882929e-01 -3.88006955e-01 -3.10198021e+00  1.42735824e-01\n",
      "  2.54218411e-02  3.43737453e-02 -3.86882335e-01  1.29919454e-01\n",
      "  9.65537783e-03 -6.84408247e-02 -6.45794809e-01  2.11611971e-01\n",
      " -1.06880002e-01 -2.65290644e-02 -3.70495804e-02  1.79707289e-01\n",
      "  3.50215216e-03 -1.81693211e-01 -2.63573498e-01 -1.48388952e-01\n",
      " -2.16333359e-01 -5.04832976e-02  3.58187519e-02 -3.04648191e-01\n",
      "  3.23388994e-01  1.26035241e-02  3.38362783e-01  2.75875442e-03\n",
      "  4.37855691e-01 -4.28804308e-01 -1.60982490e-01 -1.41987935e-01\n",
      "  2.96794951e-01  2.20471807e-02  2.99453914e-01  1.14011765e-01\n",
      "  4.19799313e-02  2.43781433e-01 -8.31898823e-02  1.51189655e-01\n",
      "  2.37276629e-02  4.46827531e-01  5.25962003e-02  1.48401335e-01\n",
      " -1.13651752e-01  2.10991517e-01 -7.23748431e-02  1.47921607e-01\n",
      "  1.26999587e-01  1.08824804e-01  4.19985533e-01  1.03714719e-01\n",
      "  6.56118523e-03  2.47460738e-01  2.75254220e-01  2.17760250e-01\n",
      " -1.86255217e-01 -8.78639892e-02  5.43244302e-01  2.08339542e-01\n",
      " -1.50413677e-01  1.40232965e-01  2.52308518e-01 -6.04627468e-03\n",
      "  2.64440980e-02  3.26144576e+00 -4.61501256e-03  8.27470794e-02\n",
      "  1.28303066e-01  2.30337698e-02 -1.63372695e-01  2.64405519e-01\n",
      " -2.69788075e-02 -9.66096595e-02  1.73989981e-01 -5.43363579e-02\n",
      " -5.03524542e-02 -1.73901469e-02  1.09063894e-01  1.08084679e-01\n",
      " -1.83604166e-01  3.06502581e-01  4.34094489e-01 -8.42917245e-03\n",
      " -6.63593337e-02  6.09059036e-01 -1.00317344e-01 -3.97523463e-01\n",
      "  2.88350489e-02 -3.41689110e-01 -2.16918439e-02  1.85429841e-01\n",
      " -1.71638176e-01  5.53668261e-01  4.05293107e-01 -9.56438184e-02\n",
      " -1.39999334e-02  9.98449996e-02 -6.90991655e-02 -4.70901094e-02\n",
      "  2.68591285e-01  2.45202899e-01  8.00094754e-02  1.94286913e-01\n",
      " -5.10906756e-01 -9.29328129e-02  3.27985175e-02  5.24665825e-02\n",
      " -3.74362677e-01 -2.24638283e-01 -6.01352006e-02 -1.56439126e-01\n",
      " -3.23204905e-01  2.18588114e-01 -1.41285941e-01  1.40743926e-01\n",
      "  1.75799012e-01 -1.30875260e-01 -4.02342454e-02 -8.76348391e-02\n",
      " -3.46713871e-01  1.74899325e-02  5.97071238e-02 -3.21252197e-01\n",
      " -3.04703806e-02 -5.89477643e-02 -1.03313103e-01 -2.32620865e-01\n",
      "  3.68991315e-01 -8.96688029e-02 -6.77370355e-02 -4.52227034e-02\n",
      " -2.47482866e-01 -4.48478794e+00  4.19580601e-02  2.25859478e-01\n",
      "  2.61040002e-01 -2.07757428e-01 -1.16848595e-01 -1.54393032e-01\n",
      " -2.07492888e-01  3.80890280e-01  4.09842134e-02 -9.51014925e-03\n",
      " -1.62417695e-01 -1.68930218e-01  9.07721147e-02 -2.84366339e-01\n",
      "  2.35637516e-01  7.25131929e-02  3.19374651e-01  1.45836562e-01\n",
      " -1.55368015e-01  1.14971384e-01  4.10116255e-01  2.51992315e-01\n",
      " -1.18155226e-01  1.32711425e-01 -1.11983247e-01  2.32351869e-02\n",
      " -2.84479141e-01  1.29167125e-01  3.55672568e-01  1.14179673e-02\n",
      "  4.17227119e-01 -4.24187295e-02 -1.39847741e-01  2.39355102e-01\n",
      " -3.55884218e+00 -2.25865245e-01 -1.02679014e-01 -6.15888909e-02\n",
      "  2.13922784e-01  1.03791699e-01  9.19393301e-02  2.35988181e-02\n",
      "  1.60480291e-01  2.13075876e-01  1.22143038e-01  9.04428959e-02\n",
      "  7.44479448e-02 -1.64701179e-01 -1.40486002e-01 -1.66612223e-01\n",
      " -5.79084270e-02  1.25443488e-01 -1.95033014e-01  3.49855781e-01\n",
      " -8.97522420e-02 -3.12245369e-01 -1.01752043e-01  1.85133919e-01\n",
      " -1.42774165e-01  1.29223540e-01 -5.28136730e-01  1.62650287e-01\n",
      "  1.53540261e-02  2.02109162e-02 -3.74325067e-01 -1.96600780e-01\n",
      " -2.16886029e-01  4.28140372e-01  9.83327106e-02 -5.31325676e-02\n",
      " -1.88728094e-01  8.70937183e-02  1.75409764e-01 -2.52990544e-01\n",
      " -1.01049639e-01  4.85827327e-01  1.45261332e-01  2.79351413e-01\n",
      " -5.45240864e-02  8.95383656e-02 -8.21768343e-02 -3.03141892e-01\n",
      " -1.61889061e-01  2.43546546e-01  6.13164343e-02 -1.52852446e-01\n",
      "  6.67735994e-01 -9.06357020e-02  2.12142333e-01  2.47617036e-01\n",
      "  1.38759181e-01 -1.82435382e-02  1.60505235e-01 -1.02978870e-01\n",
      "  3.88527751e-01 -2.01887898e-02  2.67885238e-01  1.91356182e-01\n",
      " -1.90366834e-01 -2.20042780e-01 -8.27400163e-02 -1.26757771e-01\n",
      "  5.33385724e-02 -2.91758806e-01 -2.14728907e-01 -1.11527175e-01\n",
      " -1.89469829e-01 -6.15737438e-01 -1.47092402e-01 -1.48278117e-01\n",
      " -8.81299004e-02 -1.44160213e-02 -1.38863817e-01  2.31716901e-01\n",
      " -4.79037344e-01  9.77119952e-02  2.10831463e-01  1.22504607e-01\n",
      " -7.27684125e-02 -7.94715434e-02 -3.32238115e-02 -3.73215318e-01\n",
      " -1.15678897e-02 -1.40303159e-02  1.15149327e-01  1.56557947e-01\n",
      "  1.98508233e-01 -1.03664317e-03  4.87307250e-01  6.40342990e-03\n",
      "  3.28043431e-01 -2.96366692e-01 -2.55536646e-01  1.05791382e-01\n",
      " -1.03724003e-01 -3.27485353e-01 -2.94751078e-02 -1.94822729e-01\n",
      " -1.79005340e-01  2.44557008e-01  6.56021982e-02 -3.43122520e-02\n",
      " -1.98806882e-01 -1.76189356e-02  1.58087552e-01 -2.21715681e-03\n",
      "  1.86279297e-01  2.45952964e-01  9.08474803e-01 -2.37540156e-01\n",
      " -4.30346131e-01 -1.07983738e-01  1.75747529e-01 -5.29294014e-02\n",
      "  1.04635932e-01  1.45194262e-01 -2.14770243e-01  4.39300895e-01\n",
      " -1.96363151e-01 -4.25478697e-01 -4.59359080e-01  3.51422466e-02\n",
      "  1.70939833e-01 -2.46098321e-02  8.84061381e-02 -1.12850577e-01\n",
      "  7.73101998e-03 -5.39680719e-01  1.41633466e-01 -7.13794231e-02\n",
      "  3.43222246e-02 -9.06049535e-02 -1.55204356e-01  1.48593439e-02\n",
      "  3.78961086e-01 -1.44469365e-01  4.56814878e-02  4.05404776e-01\n",
      " -7.30200782e-02 -1.47832602e-01  7.13894367e-02 -1.65229872e-01\n",
      " -3.97672020e-02  2.80888915e-01  3.29478644e-02 -2.75833517e-01\n",
      "  2.26924017e-01 -8.58237743e-02 -4.45612401e-01  2.37181470e-01\n",
      "  2.21301690e-02 -3.67894247e-02 -1.74046196e-02  1.13446735e-01\n",
      "  3.38383645e-01  1.05951644e-01 -6.64437354e-01 -1.46185145e-01\n",
      "  9.34689492e-02  1.65568471e-01  2.89251357e-01 -1.85502082e-01\n",
      " -1.16912229e-02  5.59209920e-02  2.37773210e-01  9.23731700e-02\n",
      "  8.24469775e-02 -1.07736178e-01  2.61554122e-01  1.58976510e-01\n",
      "  3.18232298e-01 -3.37529480e-02 -3.65338661e-02  5.32108545e-01\n",
      "  2.23473310e-01  4.06837761e-01  1.31795675e-01  3.18531573e-01\n",
      " -5.01792550e-01  1.38532162e-01  8.76001939e-02  1.04205601e-01\n",
      " -2.72773027e-01  2.66429305e-01 -1.35822609e-01  4.17643189e-02\n",
      "  1.75522521e-01 -2.33819082e-01 -4.02282804e-01  5.16465977e-02\n",
      " -2.21925288e-01  8.28175470e-02  9.79948044e-02 -1.86859563e-01\n",
      "  4.31172699e-01  1.74477994e-01  2.15012148e-01  3.38799983e-01\n",
      "  4.77155894e-01 -9.27841142e-02  2.03094289e-01 -7.43441433e-02\n",
      " -3.04017179e-02 -2.19908044e-01  2.53564686e-01  2.75916696e-01\n",
      "  1.95943758e-01  1.13531135e-01 -6.50585815e-02 -3.52617741e-01\n",
      "  3.39424819e-01  1.84753045e-01 -9.69830602e-02 -1.75885335e-01\n",
      "  2.00131506e-01 -7.75262043e-02  4.95465070e-01 -9.53429751e-03\n",
      "  1.15022764e-01  2.50273287e-01  1.25262499e-01 -5.22193372e-01\n",
      " -3.74536142e-02  1.00929163e-01  2.76555687e-01 -1.22246034e-01\n",
      " -4.39869128e-02  1.35749921e-01  3.90242010e-01 -1.31203204e-01\n",
      " -3.21663946e-01  1.25597179e-01  9.08564478e-02  1.97237462e-01\n",
      " -1.92230076e-01 -1.75139949e-01 -7.32290186e-03  1.35301411e-01\n",
      " -4.00715284e-02 -5.04813716e-02  1.42247900e-01  4.35886830e-02\n",
      " -1.57416448e-01  1.46606207e-01 -3.86655867e-01  2.38377497e-01\n",
      " -1.30628264e-02 -3.42019230e-01  3.69963080e-01  8.76117572e-02\n",
      " -1.32397085e-01  8.31224844e-02 -1.56797394e-01  1.23713709e-01\n",
      " -3.08644652e-01  1.16928019e-01 -3.21145266e-01 -2.69348592e-01\n",
      " -1.45591944e-01  3.17733318e-01  2.10423797e-01  1.66049927e-01\n",
      "  1.51195347e-01  2.50248373e-01  2.53356665e-01  3.36762041e-01\n",
      " -2.60061234e-01  3.20860416e-01  7.27883577e-02 -1.96634680e-01\n",
      " -3.01590353e-01 -2.43307069e-01  3.22114885e-01 -2.43908972e-01\n",
      "  2.57156110e+00 -4.03465591e-02 -5.37718423e-02  3.72538328e-01\n",
      "  3.31970841e-01 -2.02863291e-02  3.42821777e-01 -1.05419360e-01\n",
      " -7.23055005e-02 -6.23609722e-02  1.37881681e-01 -2.96366185e-01\n",
      "  4.46028590e-01 -1.60807997e-01 -3.52707356e-01  7.43726864e-02\n",
      " -2.83907708e-02 -2.00240567e-01  2.56988317e-01 -1.63020015e-01\n",
      "  9.36994180e-02 -7.81289563e-02  2.65703797e-02  2.88918823e-01\n",
      " -2.63042450e-01 -2.00958803e-01 -8.47629383e-02  4.93125692e-02\n",
      " -1.41978204e-01 -1.51457250e-01  2.21509740e-01  8.20208713e-03\n",
      "  2.22062469e-01  8.84175599e-02 -4.23133969e-02  2.67577529e-01\n",
      "  7.30356395e-01 -3.04582655e-01  1.32441685e-01 -3.30231369e-01\n",
      " -1.45009190e-01 -2.86501553e-02 -2.47037299e-02  6.69836551e-02\n",
      "  2.13983744e-01  8.18922669e-02 -1.33137614e-01 -2.18843505e-01\n",
      "  2.43079618e-01  7.32182413e-02  3.56511533e-01  2.01181889e-01\n",
      " -9.34888050e-03  3.63335311e-02 -3.43235210e-02  4.38610390e-02\n",
      " -2.13939190e-01 -5.14619574e-02  7.85606056e-02  6.28765702e-01\n",
      "  2.12244675e-01  1.12824306e-01 -1.05410799e-01  1.50509983e-01\n",
      "  2.59167068e-02 -1.24760285e-01  1.35840774e-01 -4.03054923e-01\n",
      "  1.91797853e-01  1.85039818e-01 -2.68992841e-01 -5.56377321e-02\n",
      "  1.80814520e-01  1.50030285e-01  1.55304387e-01 -1.23378582e-01\n",
      "  1.59028783e-01 -7.60759488e-02 -3.26948464e-02 -3.50469780e+00\n",
      " -4.57055449e-01  6.05102740e-02  1.19344711e-01 -6.35160431e-02\n",
      "  1.29174367e-01 -1.08045386e-02  6.24951981e-02  2.80049052e-02\n",
      " -7.95626938e-02  1.97782680e-01 -1.31778538e-01 -3.88733707e-02\n",
      "  3.06426436e-01  1.88335061e-01 -3.08370769e-01 -2.75473148e-01\n",
      " -2.74733543e-01 -3.87961388e-01  2.73445636e-01  1.79475680e-01\n",
      " -4.50713374e-02 -1.04446344e-01 -4.52635735e-02  4.13849913e-02\n",
      "  3.49536464e-02  8.77501294e-02  3.60960573e-01  9.89759620e-03\n",
      " -3.63127589e-01 -1.01200983e-01  1.57689691e-01 -3.41203511e-01\n",
      "  4.65984270e-03  4.45281297e-01 -4.28796262e-02  2.65903294e-01\n",
      " -2.19058871e-01 -2.08588004e-01  1.07189864e-01  2.14206390e-02\n",
      "  1.79277807e-01  6.40751839e-01 -1.89057156e-01  1.24367897e-03\n",
      " -1.97954580e-01  2.36080572e-01 -1.17351219e-01  1.37345150e-01\n",
      " -4.19880152e-01 -3.06904465e-01  1.62032232e-01 -1.51516259e-01\n",
      " -1.88555226e-01  1.40451163e-01 -1.46393940e-01  2.47985691e-01\n",
      "  3.95363569e-02  1.32261306e-01  9.85962003e-02  1.01255752e-01\n",
      " -4.64882292e-02 -6.30631596e-02 -7.09276944e-02 -1.52688906e-01\n",
      " -1.42156303e-01 -3.86925600e-02 -3.65777075e-01 -7.73460567e-02\n",
      "  6.41376972e-02  1.99419066e-01  2.54889131e-01  4.46378499e-01\n",
      " -1.17312670e-01 -7.74199748e-03  2.00214952e-01 -2.16475800e-01\n",
      "  2.36026168e-01 -1.19300559e-01 -8.00205320e-02  1.41473059e-02\n",
      " -1.33824393e-01  3.01874310e-01  4.31657545e-02 -2.84888715e-01\n",
      " -8.57103920e+00 -1.08635843e-01  6.86087236e-02  1.17021136e-01\n",
      " -1.52671887e-02 -3.17293018e-01  2.44799674e-01  1.93023205e-01\n",
      "  1.39458831e-02 -9.17008147e-02  2.74277419e-01 -5.23392521e-02\n",
      "  1.21194854e-01  1.68660238e-01  8.15203413e-02  1.49841994e-01]\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df= pd.read_csv('vbOutput_copy.csv')\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "lr.fit(train_features, train_labels)\n",
    "lr.score(test_features, test_labels)\n",
    "pred = lr.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[223 139]\n",
      " [ 68  92]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_features,train_labels)\n",
    "rf.score(test_features, test_labels)\n",
    "haterh\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_labels,pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3207d3461d8ffe403cc264b09538f9227650cd62b12927fd34bb1e7779c851a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
